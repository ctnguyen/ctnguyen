%Texlive-full Version 3.141592-1.40.3 (Web2C 7.5.6)
%Kile Version 2.0.83

\documentclass[a4paper,10pt]{article}
\usepackage[utf8x]{inputenc}

\usepackage{lmodern}
\usepackage[a4paper]{geometry}

\usepackage{hyperref}

\usepackage{amsmath}
\usepackage{amssymb}

\usepackage{pstricks}
\usepackage{pst-node}


\begin{document}
%%%%%%%%%%%%%%%%%% DOCUMENT TITLE %%%%%%%%%%%%%%%%%%%%%%%%%
\begin{center}Memento for Usuals Probability Distributions\end{center}
%%%%%%%%%%%%%%%%%% DOCUMENT TITLE %%%%%%%%%%%%%%%%%%%%%%%%%
\section{Base }
\paragraph{Convergences and relations}
\begin{center}
\begin{pspicture}(-7,-2)(7,2)
%\psline(-7,-2)(7,2)
\rput(-1, 1){\Rnode{as}{\psframebox{$X_n \xrightarrow{a.s} X$}}}
\rput(-1,-1){\Rnode{Lp}{\psframebox{$X_n \xrightarrow{\textbf{L}^p} X$}}}
\rput(-4,-1){\Rnode{Lq}{\psframebox{$X_n \xrightarrow{\textbf{L}^q} X$}}}
\rput( 2, 0){\Rnode{P}{\psframebox{$X_n \xrightarrow{\mathbb{P}} X$}}}
\rput( 5, 0){\Rnode{L}{\psframebox{$X_n \rightsquigarrow X$}}}
\rput( -5, 0.5){\Rnode{cond}{$ _{0<p<q \leq \infty} \Rightarrow \begin{array}{l}
                                                                     |.|_p \leq |.|_q \\
								    \textbf{L}^q \subset \textbf{L}^p
                                                                    \end{array}$}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\ncline[linestyle=dashed]{->}{Lq}{Lp}
\ncline[linestyle=dashed]{->}{as}{P}
\ncline[linestyle=dashed]{->}{Lp}{P}
\ncline[linestyle=dashed]{->}{P}{L}
\end{pspicture}
\end{center}


\paragraph{Law of large numbers}
\[
\text{if} \hspace{5mm} (X_{n})_{(n\geqslant 0)} \in \textbf{L}^1 \text{  i.i.d,} \hspace{5mm} \text{ then  } \hspace{5mm}  \overline{X}_n\xrightarrow{a.s} \mathbb{E}[X_{0}]  
\]
\paragraph{Central Limit Theorem}
\[
\text{if} \hspace{5mm} (X_{n})_{(n\geqslant 0)} \in \textbf{L}^2 \text{  i.i.d,} \hspace{5mm} \text{ then  } \hspace{5mm}
\frac{\overline{X}_n - \mu}{\frac{\sigma}{\sqrt{n}}} \rightsquigarrow   \mathcal{N}(0,1)
 \hspace{5mm}  \text{    or} \hspace{5mm}  
\sqrt{n}(\overline{X}_n - \mu) \rightsquigarrow   \mathcal{N}(0,\sigma^{2})
\]

\paragraph{Slutsky's Theorem}
\[
\text{if} \hspace{5mm} 
\left\{ 
\begin{array}{l}
X_n \rightsquigarrow X \\
Y_n \xrightarrow{\mathbb{P}} c 
\end{array}\right. 
\hspace{5mm} \text{ then  } \hspace{5mm}
\left\{ 
\begin{array}{l}
X_n + Y_n \rightsquigarrow X+c \\
X_n . Y_n \rightsquigarrow  c.X 
\end{array}\right. 
\]

\paragraph{The Delta Method}
\[
\text{if} \hspace{5mm} 
\left\{ 
\begin{array}{l}
\sqrt{n}(U_n - \mu) \rightsquigarrow   \mathcal{N}(0,\sigma^{2}) \\
g \in \mathbb{C}^1_{(\mu)}
\end{array}\right. 
\hspace{5mm} \text{ then  } \hspace{5mm}
\sqrt{n}(g(U_n) - g(\mu) ) \rightsquigarrow   \mathcal{N}(0,\sigma^{2}[g'(\mu)]^2) 
\]

\paragraph{Markov's inequality}
\[
\text{for all}\hspace{5mm} \varepsilon > 0, p>0, X\in \textbf{L}^p \hspace{20mm} \mathbb{P}(|X| \geq \varepsilon) \leq \frac{\mathbb{E}[|X|^p]}{\varepsilon ^p}
\]
\paragraph{Bienayme-Tchebychev's inequality}
\[
\text{for all  } \hspace{5mm} \varepsilon > 0, X\in \textbf{L}^2 \hspace{20mm} \mathbb{P}(|X- \mathbb{E}X| \geq \varepsilon) \leq \frac{\textbf{Var}[X]}{\varepsilon ^2}
\]
\paragraph{Berry-Esseen's inequality}
\[
\text{if} \hspace{5mm} (X_{i})_{(0\leqslant i \leqslant n)} \in \textbf{L}^3 \text{  i.i.d,} \hspace{5mm} \text{ then  } \hspace{5mm}
\sup_{t\in \mathbb{R}} \left| \mathbb{P}(\frac{\overline{X}_n - \mu}{\frac{\sigma}{\sqrt{n}}} \leq t) - F_{\mathcal{N}_{0,1}}(t) \right| 
\leq \frac{\mathbb{E}[|X_i - \mu|^3]}{\sigma^3 \sqrt{n}}
\]
\paragraph{Hoeffding's inequality}
if $(X_{i})_{(0\leqslant i \leqslant n)}$ independant bounded $X_i \in [a_i,b_i]$, then
\[
\mathbb{P}(\overline{X}_n- \mathbb{E}[\overline{X}_n] \geq t) \leq exp\left(-\frac{2n^2t^2}{\sum_{i=0}^{n} (b_i-a_i)^2}\right) 
\hspace{5mm} \text{ for all } t >0
\]

\paragraph{Dvoretzky–Kiefer–Wolfowitz inequality}
if $(X_{i})_{(0\leqslant i \leqslant n)}$ i.i.d  $X_i \sim F $, and its empirical distribution $F_n$ 
\[
\left\{
\begin{array}{l}
\mathbb{P}( \sup_{x\in \mathbb{R}} ( {F}_n(x)- F(x) ) > \varepsilon ) \leq e^{-2n\varepsilon^2} 
\hspace{5mm} \text{ for all } \varepsilon \geq \sqrt{\frac{1}{2n}log2} \\ \\
\mathbb{P}( \sup_{x\in \mathbb{R}} | {F}_n(x)- F(x) | > \varepsilon ) \leq 2.e^{-2n\varepsilon^2} 
\hspace{5mm} \text{ for all } \varepsilon > 0
\end{array}
\right.
\]


\paragraph{Kolmogorov's inequality}
if $(X_{i})_{(0\leqslant i \leqslant n)} \in \textbf{L}^2$ independant, $\mathbb{E}[X_i]=0$, then
\[
\mathbb{P}\left( \max_{0\leqslant k \leqslant n}\left| \sum_{i=0}^{k} X_i  \right| 
\geq \varepsilon \right) \leq \frac{1}{\varepsilon^2} \sum_{i=0}^{n} \textbf{Var}[X_i]
\hspace{5mm} \text{ for all } \varepsilon >0
\]

\paragraph{Gamma Function}
\[
\Gamma(z) = \int_{0}^{\infty} t^{z-1}e^{-t}dt 
\hspace{30mm}  \Gamma(1) = 1 
\hspace{10mm}  \Gamma(z+1) = z\Gamma(z) 
\hspace{10mm}  \Gamma(n) = (n-1)! 
\]
\paragraph{Beta Function}
\[
\beta(x,y)=  \int_{0}^{1}  t^{x-1}(1-t)^{y-1}dt  \hspace{30mm} \beta(y,x)=\beta(x,y)= \frac{\Gamma(x)\Gamma(y)}{\Gamma(x+y)}
\]
\paragraph{Binomial Coefficient k-combination of n elements}
\[
\textbf{C}^{k}_{n} = \binom{n}{k} = \frac{n!}{k!(n-k)!}
\hspace{30mm} \textbf{C}^{k}_{n} = \textbf{C}^{n-k}_{n} 
\hspace{10mm} \textbf{C}^{k+1}_{n+1} = \textbf{C}^{k}_{n} + \textbf{C}^{k+1}_{n} 
\]

\paragraph{Generating Function (discrete variables)}
\[
\textbf{G}_{X}(t)= \mathbb{E}[t^{\textbf{X}}] = \sum t^{x}.p(x)
\hspace{6mm} \mathbb{P}(\textbf{X}=k) = \frac{\textbf{G}_{X}^{(k)}(0)}{k!}
\hspace{6mm} \textbf{G}_{X}^{(m)}(1)  = \mathbb{E}[(X)(X-1)...(X-m+1)]
\]
\paragraph{Characteristic Function}
\[
\mathbb{R}^{n}
\left\{
\begin{array}{l}
\varphi_{X}(t)= \mathbb{E}[e^{i<t,X>}] = \int_{\mathbb{R}} e^{i<t,x>} . f_{X}(x).dx \\
f_{X}(x) = \frac{1}{2\pi}\int_{\mathbb{R}} e^{i<t,x>} . \varphi_{X}(t).dt
\end{array}\right. 
\hspace{5mm}
(\mathbb{E}[X^{k}]< \infty) \Rightarrow 
\left\{
\begin{array}{l}
\varphi_{X}^{(r)}(t)= i^{r}\mathbb{E}[X^{r}e^{itX}] \\
\varphi_{X}^{(r)}(0)= i^{r}\mathbb{E}[X^{r}]
\end{array}\right. 
\]


\section{Discrete Probability Distributions}

\paragraph{Bernouilli} $X\sim \mathcal{B}(\theta)$ when, 
\[
X \in \{0,1\} , 
\hspace{10mm}
\left\{
\begin{array}{l}
P(X=1)=\theta \\
P(X=0)=1-\theta
\end{array}\right.
\hspace{20mm}
\mathbb{E}[X^k]=\theta,
\hspace{10mm}
\left\{
\begin{array}{l}
\mathbb{E}[X]=\theta \\
\textbf{Var}[X]=\theta (1-\theta)
\end{array}\right.
\]

\paragraph{Binomial} $X\sim \mathcal{B}(n,\theta)$ when,
\[
X \in \{0,1 .. , n\} , 
\hspace{10mm}
P(X=k)=C^k_n\theta ^k (1-\theta)^{n-k} 
\hspace{10mm}
\left\{
\begin{array}{l}
\mathbb{E}[X]=n\theta \\
\textbf{Var}[X]=n \theta (1-\theta) 
\end{array}\right.
\]
Binomial variable is the sum i.i.d of n Bernouilli variable : $\sum_1^n \mathcal{B}(\theta) \stackrel{\textbf{i.i.d}}{\sim}  \mathcal{B}(n,\theta) $

\paragraph{Poisson} $X\sim \mathcal{P}(\lambda)_{\lambda>0}$ when,
\[
X \in \mathbb{N} , 
\hspace{10mm}
P(X=k)= e^{-\lambda}\frac{e^{\lambda^k}}{k!}
\hspace{10mm}
\left\{
\begin{array}{l}
\mathbb{E}[X]=\lambda \\
\textbf{Var}[X]=\lambda
\end{array}\right.
\]
The sum of independant \textbf{Poisson} variable is a \textbf{Poisson} variable of sum :
\[
\text{if  } 
\left\{
\begin{array}{l}
X_i \sim \mathcal{P}(\lambda_i) \textbf{independant} \\
S_n = \sum_{1}^{n} X_i \\
\lambda = \sum_{1}^{n} \lambda_i
\end{array}\right.
\hspace{10mm} \text{then} \hspace{10mm}
S_n \sim \mathcal{P}(\lambda)
\]
When $n\theta \approx \lambda$ we have $\mathcal{B}(n,\theta) \approx \mathcal{P}(\lambda)$

\paragraph{Uniform} $X\sim \mathcal{U}_{[a,b]}$ when $X \in [a,b]$ and,
\[
f_{X}(x) = \frac{1}{b-a}\mathbf{1}_{[a,b]}
\hspace{10mm}
\left\{
\begin{array}{l}
\mathbb{E}[X^k]=\frac{b^{k+1}-a^{k+1}}{(k+1)(b-a)} \\
\mathbb{E}[X]=\frac{a+b}{2} \\
\textbf{Var}[X]=\frac{(b-a)^2}{12} 
\end{array}\right.
\hspace{10mm}
\left\{
\begin{array}{l}
\textbf{F}_X(x) = \frac{x-a}{b-a}\mathbf{1}_{[a,b[} + \mathbf{1}_{[b,\infty[} \\
\varphi_{X}(t) = \frac{e^{itb}-e^{ita}}{it(b-a)}
\end{array}\right.
\]

\paragraph{Exponential} $X\sim \mathcal{E}(\lambda)_{\lambda>0}$ when $X \in [0,\infty[$ and,
\[
f_{X}(x) = \lambda e^{-\lambda x} \mathbf{1}_{[0,\infty[}
\hspace{10mm}
\left\{
\begin{array}{l}
\mathbb{E}[X^k]=\frac{k!}{\lambda^k} \\
\mathbb{E}[X]=\frac{1}{\lambda} \\
\textbf{Var}[X]=\frac{1}{\lambda^2} 
\end{array}\right.
\hspace{10mm}
\left\{
\begin{array}{l}
\textbf{F}_X(x) = (1- e^{-\lambda x})\mathbf{1}_{[0,\infty[} \\
\varphi_{X}(t) = \frac{\lambda}{\lambda - it}
\end{array}\right.
\]
Some relations
\[
\mathcal{E}(\lambda) = \gamma(1,\lambda)
\hspace{10mm}
aX \sim \gamma(1,\frac{\lambda}{a})
\hspace{10mm}
X_{(1)} \sim \mathcal{E}(n\lambda)
\]

\paragraph{Gamma} $X\sim \gamma(a,b)_{a>0,b>0}$ when $X \in [0,\infty[$ and,
\[
f_{X}(x) = \frac{b^a}{\Gamma(a)} x^{a-1} e^{-bx} \mathbf{1}_{[0,\infty[}
\hspace{10mm}
\left\{
\begin{array}{l}
\mathbb{E}[X^k]=\frac{\Gamma(a+k)}{b^k\Gamma(a)} \\
\mathbb{E}[X]=\frac{a}{b} \\
\textbf{Var}[X]=\frac{a}{b^2} 
\end{array}\right.
\hspace{10mm}
\left\{
\begin{array}{l}
\textbf{F}_X(x) = \frac{\gamma(a,bx)}{\Gamma(a)} (*)  \\
\varphi_{X}(t) = (\frac{b}{b - it})^a
\end{array}\right.
\]
\[
\varepsilon X \sim \gamma(a,\frac{b}{\varepsilon})
\hspace{10mm}
\overline{X}_n \sim \gamma(n,n\lambda)
\hspace{20mm}
X_i \stackrel{\textbf{i.i.d}}{\sim} \gamma(a_i,b) \Longrightarrow \sum X_i \sim \gamma(\sum a_i, b)
\]
(*) The imcomplete gamma function is defined by $\gamma(a,x) = \int_{0}^{x} t^{a-1}e^{-t}dt $

\paragraph{Normal} $X \sim \mathcal{N}(\mu,\sigma^2)$ when $X \in \mathbb{R}$ and,
\[
f_{X}(x) = \frac{1}{\sigma \sqrt{2\pi}} exp (-\frac{(x-\mu)^2}{2\sigma^2})
\hspace{10mm}
\left\{
\begin{array}{l}
\mathbb{E}[X]=\mu \\
\textbf{Var}[X]=\sigma^2
\end{array}\right.
\hspace{10mm}
\left\{
\begin{array}{l}
\textbf{F}_X(x) =  \frac{1}{2}(1+erf(\frac{x}{\sqrt{2}})) \\
\varphi_{X}(t) = exp(i\mu t - \frac{1}{2}\sigma^2 t^2)
\end{array}\right.
\]
\[
\frac{X - \mu}{\sigma} \sim \mathcal{N}(0,1)
\hspace{10mm}
f_{X}(x) = \frac{1}{\sigma}f_{\mathcal{N}(0,1)}(\frac{x-\mu}{\sigma})
\hspace{10mm}
\left\{
\begin{array}{l}
F^{\mathcal{N}(0,1)} (\alpha) + F^{\mathcal{N}(0,1)}(-\alpha) = 1 \\
q^{\mathcal{N}(0,1)}_{1-\alpha} = - q^{\mathcal{N}(0,1)}_{\alpha} 
\end{array}\right.
\]

\paragraph{Chi-squared} $X\sim \chi^2_n$ when  $X \in \mathbb{R}_+$ and
\[
\left[
\begin{array}{l}
X \sim \gamma(\frac{n}{2}, \frac{1}{2}) \\
X = \sum^{n}_{\textbf{i.i.d}} [ \mathcal{N}(0,1) ]^2
\end{array}\right.
\hspace{10mm}
\left\{
\begin{array}{l}
\mathbb{E}[X]= n \\
\textbf{Var}[X]=2n
\end{array}\right.
\]


\paragraph{Student} $T\sim \textbf{t}_m$ when  $T \in \mathbb{R}$ and
\[
\left[
\begin{array}{l}
Y \bot Z                \\
Y \sim \mathcal{N}(0,1) \\
Z \sim  \chi^2_m  
\end{array}\right.
\hspace{3mm} \Rightarrow
T=\frac{Y}{\sqrt{\frac{Z}{m}}} \sim \textbf{t}_n
\hspace{10mm}
\textbf{Var}[T]= \frac{m}{m-2} , \text{  when } m>2 
\]


\paragraph{Fisher} $F\sim \mathcal{F}_{(m_1,m_2)}$ when  $F \in \mathbb{R}_+$ and
\[
\left[
\begin{array}{l}
X_1 \bot X_2            \\
X_1 \sim \chi^2_{(m_1)} \\
X_2 \sim \chi^2_{(m_2)}
\end{array}\right.
\hspace{3mm} \Rightarrow
F=\frac{\frac{X_1}{m_1}}{\frac{X_2}{m_2}} \sim \mathcal{F}_{(m_1,m_2)}
\hspace{10mm}
F\sim \mathcal{F}_{(m_1,m_2)} \Rightarrow \frac{1}{F} \sim \mathcal{F}_{(m_2,m_1)} 
\]



\section{Gaussian}
\paragraph{Cochran's theorem}

\paragraph{Gaussian samples}
\[
\text{if }
\left\{
\begin{array}{l}
X_i \stackrel{\textbf{i.i.d}}{\sim} \mathcal{N}(\mu, \sigma^2) \\
\overline{X}_n = \frac{1}{n}\sum^n_1 X_i \\
S^2 = \frac{1}{n-1}\sum^n_1 (X_i - \overline{X}_n) 
\end{array}\right.
\hspace{10mm}
\text{then }
\left\{
\begin{array}{l}
\frac{\sqrt{n} (\overline{X}_n - \mu)}{\sigma} \sim \mathcal{N}(0,1) \\
\frac{1}{\sigma2}\sum^n_1 (X_i - \mu)^2 \sim \chi^2_{(n)} \\
\frac{1}{\sigma2}\sum^n_1 (X_i - \overline{X}_n)^2 \sim \chi^2_{(n-1)} \\
\frac{\sqrt{n} (\overline{X}_n - \mu)}{S} \sim \textbf{t}_{(n-1)}
\end{array}\right.
\]








\end{document}